{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess.engine\n",
    "import chess \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import chess.pgn \n",
    "from stockfish import Stockfish\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "import chess\n",
    "import chess.pgn\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "import sys\n",
    "from stockfish import Stockfish\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from maia_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(game):\n",
    "    # Read the next game\n",
    "    features = defaultdict(int)\n",
    "    stockfish=Stockfish(\"../stockfish/stockfish-windows-x86-64-avx2.exe\")\n",
    "    stockfish.set_depth(15)#How deep the AI looks\n",
    "    features = defaultdict(int)\n",
    "    features[\"moves\"] = [str(move) for move in game.mainline_moves()]\n",
    "    features[\"WhiteElo\"] = game.headers.get('WhiteElo', '')\n",
    "    features[\"BlackElo\"] = game.headers.get('BlackElo', '')\n",
    "    features[\"white\"] = game.headers.get('White', '')\n",
    "    features[\"black\"] = game.headers.get('Black', '')\n",
    "    try:\n",
    "        mm = maia_cpl(features, stockfish)\n",
    "        features[\"maia_cpl_w\"] = mm[\"cplw\"]\n",
    "        features[\"maia_cpl_b\"] = mm[\"cplb\"]\n",
    "    except:\n",
    "        return features\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pgn_file_path = \"../data/landing/FIDE_openings.pgn\"\n",
    "\n",
    "games = []\n",
    "pgn_file = open(pgn_file_path)\n",
    "game = chess.pgn.read_game(pgn_file)\n",
    "\n",
    "start = 0\n",
    "limit = 10000\n",
    "count = 0\n",
    "while game is not None:\n",
    "    #features = extract_features(game)\n",
    "    games.append(game)\n",
    "\n",
    "    count += 1\n",
    "    if count == limit:\n",
    "        break\n",
    "    game = chess.pgn.read_game(pgn_file)\n",
    "\n",
    "pgn_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--weights=lc0_windows\\models\\maia-1600.pb.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<UciProtocol (pid=22536)>: stderr >>        _\n",
      "<UciProtocol (pid=22536)>: stderr >> |   _ | |\n",
      "<UciProtocol (pid=22536)>: stderr >> |_ |_ |_| v0.31.1 built Aug 11 2024\n",
      "<UciProtocol (pid=22536)>: stderr >> Found configuration file: c:\\pc_coding\\Finding-Elo\\maia.chess\\lc0_windows/lc0.config\n",
      "<UciProtocol (pid=21652)>: stderr >>        _\n",
      "<UciProtocol (pid=21652)>: stderr >> |   _ | |\n",
      "<UciProtocol (pid=21652)>: stderr >> |_ |_ |_| v0.31.1 built Aug 11 2024\n",
      "<UciProtocol (pid=21652)>: stderr >> Found configuration file: c:\\pc_coding\\Finding-Elo\\maia.chess\\lc0_windows/lc0.config\n",
      "<UciProtocol (pid=22536)>: stderr >> Loading weights file from: lc0_windows\\models\\maia-1600.pb.gz\n",
      "<UciProtocol (pid=22536)>: stderr >> Creating backend [cuda-auto]...\n",
      "<UciProtocol (pid=22536)>: stderr >> Switching to [cuda-fp16]...\n",
      "<UciProtocol (pid=22536)>: stderr >> CUDA Runtime version: 11.1.0\n",
      "<UciProtocol (pid=22536)>: stderr >> Latest version of CUDA supported by the driver: 12.6.0\n",
      "<UciProtocol (pid=22536)>: stderr >> GPU: NVIDIA GeForce RTX 3070\n",
      "<UciProtocol (pid=22536)>: stderr >> GPU memory: 7.99951 Gb\n",
      "<UciProtocol (pid=22536)>: stderr >> GPU clock frequency: 1815 MHz\n",
      "<UciProtocol (pid=22536)>: stderr >> GPU compute capability: 8.6\n",
      "<UciProtocol (pid=22536)>: stderr >> L2 cache capacity: 4194304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--weights=lc0_windows\\models\\maia-1900.pb.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<UciProtocol (pid=21652)>: stderr >> Loading weights file from: lc0_windows\\models\\maia-1900.pb.gz\n",
      "<UciProtocol (pid=21652)>: stderr >> Creating backend [cuda-auto]...\n",
      "<UciProtocol (pid=21652)>: stderr >> Switching to [cuda-fp16]...\n",
      "<UciProtocol (pid=21652)>: stderr >> CUDA Runtime version: 11.1.0\n",
      "<UciProtocol (pid=21652)>: stderr >> Latest version of CUDA supported by the driver: 12.6.0\n",
      "<UciProtocol (pid=21652)>: stderr >> GPU: NVIDIA GeForce RTX 3070\n",
      "<UciProtocol (pid=21652)>: stderr >> GPU memory: 7.99951 Gb\n",
      "<UciProtocol (pid=21652)>: stderr >> GPU clock frequency: 1815 MHz\n",
      "<UciProtocol (pid=21652)>: stderr >> GPU compute capability: 8.6\n",
      "<UciProtocol (pid=21652)>: stderr >> L2 cache capacity: 4194304\n",
      "<UciProtocol (pid=6572)>: stderr >>        _\n",
      "<UciProtocol (pid=6572)>: stderr >> |   _ | |\n",
      "<UciProtocol (pid=6572)>: stderr >> |_ |_ |_| v0.31.1 built Aug 11 2024\n",
      "<UciProtocol (pid=6572)>: stderr >> Found configuration file: c:\\pc_coding\\Finding-Elo\\maia.chess\\lc0_windows/lc0.config\n",
      "<UciProtocol (pid=768)>: stderr >>        _\n",
      "<UciProtocol (pid=768)>: stderr >> |   _ | |\n",
      "<UciProtocol (pid=768)>: stderr >> |_ |_ |_| v0.31.1 built Aug 11 2024\n",
      "<UciProtocol (pid=768)>: stderr >> Found configuration file: c:\\pc_coding\\Finding-Elo\\maia.chess\\lc0_windows/lc0.config\n",
      "<UciProtocol (pid=6572)>: stderr >> Loading weights file from: lc0_windows\\models\\maia-1900.pb.gz\n",
      "<UciProtocol (pid=6572)>: stderr >> Creating backend [cuda-auto]...\n",
      "<UciProtocol (pid=6572)>: stderr >> Switching to [cuda-fp16]...\n",
      "<UciProtocol (pid=6572)>: stderr >> CUDA Runtime version: 11.1.0\n",
      "<UciProtocol (pid=6572)>: stderr >> Latest version of CUDA supported by the driver: 12.6.0\n",
      "<UciProtocol (pid=6572)>: stderr >> GPU: NVIDIA GeForce RTX 3070\n",
      "<UciProtocol (pid=6572)>: stderr >> GPU memory: 7.99951 Gb\n",
      "<UciProtocol (pid=6572)>: stderr >> GPU clock frequency: 1815 MHz\n",
      "<UciProtocol (pid=6572)>: stderr >> GPU compute capability: 8.6\n",
      "<UciProtocol (pid=6572)>: stderr >> L2 cache capacity: 4194304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--weights=lc0_windows\\models\\maia-1900.pb.gz\n",
      "--weights=lc0_windows\\models\\maia-1900.pb.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<UciProtocol (pid=768)>: stderr >> Loading weights file from: lc0_windows\\models\\maia-1900.pb.gz\n",
      "<UciProtocol (pid=768)>: stderr >> Creating backend [cuda-auto]...\n",
      "<UciProtocol (pid=768)>: stderr >> Switching to [cuda-fp16]...\n",
      "<UciProtocol (pid=768)>: stderr >> CUDA Runtime version: 11.1.0\n",
      "<UciProtocol (pid=768)>: stderr >> Latest version of CUDA supported by the driver: 12.6.0\n",
      "<UciProtocol (pid=768)>: stderr >> GPU: NVIDIA GeForce RTX 3070\n",
      "<UciProtocol (pid=768)>: stderr >> GPU memory: 7.99951 Gb\n",
      "<UciProtocol (pid=768)>: stderr >> GPU clock frequency: 1815 MHz\n",
      "<UciProtocol (pid=768)>: stderr >> GPU compute capability: 8.6\n",
      "<UciProtocol (pid=768)>: stderr >> L2 cache capacity: 4194304\n"
     ]
    }
   ],
   "source": [
    "chunk_size = 500  # Process 1000 games at a time\n",
    "num_chunks = len(games) // chunk_size + (1 if len(games) % chunk_size > 0 else 0)\n",
    "for i in range(13, num_chunks):\n",
    "\n",
    "    try:\n",
    "        result = []\n",
    "\n",
    "        start_index = i * chunk_size\n",
    "        end_index = min(start_index + chunk_size, len(games))\n",
    "        games_chunk = games[start_index:end_index]\n",
    "\n",
    "        for game in games_chunk:\n",
    "            features = extract_features(game)\n",
    "            result.append(features)\n",
    "\n",
    "        ndjson_file_path = f'../data/raw/fide_maia/fide_{start_index}.ndjson'\n",
    "        print(f\"saved to {ndjson_file_path}\")\n",
    "        print(\"--------------------------------------------------------\")\n",
    "        with open(ndjson_file_path, 'w') as f:\n",
    "            for item in result:\n",
    "                json.dump(item, f)\n",
    "                f.write('\\n') \n",
    "    except Exception as e:\n",
    "       # By this way we can know about the type of error occurring\n",
    "        print(\"The error is: \",e)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
